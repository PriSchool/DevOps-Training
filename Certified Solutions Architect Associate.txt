יש ללחוץ  על ctrl+shift הימניים במקלדת כדי לעבור למצב קריאה נוח יותר בעברית (align to right side)

----
IAM
----
Identity and Access Management
עדיף לא להשתמש ב-root account מעבר לקונפיגורציות ההתחלתיות, ולקנפג דברים מאוחר יותר בשימוש user ספציפי
groups מכילים משתמשים שונים שאמורים לקבל הרשאות מסויימות ברחבי החשבון, והם יכולים להיות חלק מכמה קבוצות בו בזמן.
roles עובדים באופן דומה, רק עבור מתן הרשאות לשירותים של AWS עצמם או משתמשים אחרים ולא עבור users בתוך אותו חשבון.
הרשאות נשמרות במסמכי JSON שמפרטים מה מותר או לא מותר לחברי group\role מסויימים; הרשאות יכולות גם להינתן למשתמשים שלא נמצאים ב-group/role מסויים על ידי inline policy, אך זה לא נחשב best practice ועדיף שכל המשתמשים יהיו מתוייגים בצורה כזו או אחרת. ניתן לבדוק policies בקלות על ידי שימוש בכלי IAM Policy Simulator, בכתובת https://policysim.aws.amazon.com.
ניתן לעבור עם AWS Management Console, אך במקביל ניתן להשתמש גם ב-CLI דרך מערכת ההפעלה עצמה, ב-CloudShell דרך הדפדפן או דרך SDK בשילוב עם קוד באיזו שפה שנרצה (בכדי לעבוד עם כל דרך שהיא לא management console, יש צורך לעבוד עם Access Keys שאפשר ליצור דרך תפריט security credentials אחרי גישה למשתמש ספציפי.


----
EC2
----
קיימים סוגים שונים של שרתי EC2 שאפשר להרים, כל אחד בעל יתרון מסויים על פני אחרים, כדוגמת storage, memory, computing optimized וכן הלאה.
ישנים גם גדלים ומהירויות שונות - מידע מפורט ניתן למצוא ב- www.ec2instances.info
יש באפשרותנו לגשת ל-AWS EC2 Instance Metadata, בעזרת URL שפתוח לגישה רק מתוך EC2 instances ולא מ-public, והוא יכול לתת לנו מידע חיוני אודות אותו instance כדוגמת מידע IAM Role שמשוייך אליו. URL זה הוא http://169.254.169.254/latest/meta-data.


----------------
Security Groups
----------------
קבוצות עם לוגיקה מסויימת שמאפשרת/מונעת גישה אל/מחוץ ל-EC2 מסויים, מהווה מעין firewall חיצוני למערכת EC2 - לא פועל כמו תוכנה על גבי השרת אלא מחוצה לו.
בעל אופי many to many, בתצורת הרבה קבוצות על EC2 מסויים, או קבוצה אחת להרבה EC2.
זה טוב להקים security group ספציפית עבור גישת SSH, שכן זו אחת הפעולות המסובכות בגישה ל-EC2.
ניתן להסיק מידע חשוב בעתיד מתוך הודעות שגיאה המתקבלות בעת ניסיון חיבור לשרת - אם מתקבלת הודעת "time out", כנראה שמדובר ב-security group שחסם את הגישה; אם מתקבלת הודעת "connection refused", אז ייתכן שהחיבור כן מאופשר אבל מדובר כבר בתקלה באפליקציה עצמה על גבי ה-EC2.
בתור ברירת מחדל, כל התעבורה אל תוך security group חסומה, וכל התעבורה אל מחוץ לה מאושרת.
ניתן לבצע קישור בין security groups שונים על מנת לתת אישור ישיר ביניהם ובכך לא להתעסק עם IP אלא עם ה-instances עצמם.
פורטים מוכרים:
*22-   SSH, התחברות דרך secure shell אל תוך instance של לינוקס.
*21-   FTP, העלאת קבצים לשיתוף
*22-   SFTP, דומה ל-FTP, אבל העלאת קבצים דרך SSH
*80-   HTTP, התחברות לאתרים לא מאובטחים
*443-  HTTPS, התחברות לאתרים מאובטחים
*3389- RDP, התחברות ל-instance של ווינדוס, remote desktop protocol


----
SSH
----
חיבור לתוך instance של EC2 בעזרת secure shell על מנת לבצע פעולות או תחזוקה בתוך המכונה.
מסוגל לפעול ב-mac או linux, ובנוסף בווינדוס בגרסאות 10 ומעלה.
אפשר להשתמש באופן זהה ב-Putty בכל גרסאות ווינדוס, או פשוט ב-EC2 Instance Connect שמאפשר גישה נוחה דרך הדפדפן מכל מערכת הפעלה.
על מנת להיכנס ל-instance מסויים עלינו להשתמש ב-SSH בעזרת הפקודה הבאה:
<ssh -i <path of your .pem file, containing private keys> ec2-user@<IPv4 of your EC2 instance, going to change each time you start it back up
לדוגמה-
ssh -i "C:\Users\Tomer\Desktop\Solutions Architect Associate\EC2Tutorial.pem" ec2-user@34.241.77.36
החיבור הדיפולטיבי של SSH הוא באמצעות סיסמה, אך מקובל הרבה יותר לעבוד עם key-pairs של public/private keys שאפשר ליצור במגוון דרכים שונות.
השימוש בזוג המפתחות הוא בצורה כזו שהמפתח הפרטי נשמר תמיד בסודיות מוחלטת על גבי המכונה שאנו רוצים להתחבר דרכה (המקור) - והמפתח הציבורי, זה המקושר קריפטוגרפית לאותו מפתח פרטי, צריך להישמר על גבי המכונה אלייה אנו מעוניינים להתחבר (היעד).
בצורה כזו אנו יכולים בפעם הראשונה להתחבר למכונה באמצעות SSH בעזרת סיסמה, להעתיק למכונה זו את המפתח הציבורי שלנו לתיקייה מסויימת ומאוחר יותר להתחבר בפעם השנייה והלאה כבר באמצעות SSH בשימוש זוג המפתחות, שכן אנו מקשרים בין המפתח הפרטי השמור אצלנו לבין המפתח הציבורי השמור על גבי המכונה המיועדת לחיבור.


---
IP
---
ישנם 2 סוגי IP בעולם כיום-
*IPv4, שעובד בפורמט של <0-255>.<0-255>.<0-255>.<0-255> 
סך האופציות לכתובות שונות בפורמט זה הוא מעל 4 מיליארד כתובות שונות, ועם היותו הפורמט הנפוץ כעת בעולם, ישנו מעבר הכרחי לשימוש ב-IPv6.
*IPv6, שעובד בפורמט של 128^2 כתובות, לדוגמה 2001:db8:1234::f350:2256:f3dd/64.

ישנה גם הפרדה בין 2 סוגי כתובות שכל מערכת מקבלת-
*IP ציבורי, כזה שאפשר לגשת אליו מכלל רחבי האינטרנט; טווח הכתובות הזה אינו מאפשר כפילות של 2 כתובות.
*IP פרטי, שניתן לגשת אליו רק מתוך אותה רשת פרטית שאלייה הוא שייך;
ה-IP הציבורי מתחלף בכל פעם שאנו מכבים ומדליקים מחדש instance, ולכן קיימת אופציה לשלם עבור elastic IP - אופציה לא מומלצת במיוחד אך יעילה במצבים בהם נרצה "לשמור" את כתובת IPv4 שלנו על מנת לייצר מצב תיקון תקלות תיאורטי שבו בעת נפילת שרת מסויים נוכל לתת את הכתובת הגמישה לשרת חדש.


----------------
Placement Groups
----------------
יש לנו אפשרות לשלוט על פריסת ה-instances שלנו ברמת ה-infrastructure בצד של AWS.
הכוונה היא שנוכל להחליט מראש על מיקום השרתים שאנו משכירים מצד AWS על מנת ליצור יתרונות משמעותיים לטובת הרצת השרתים שלנו.
ישנן 3 אופציות כשמדובר ב-placement groups:
*Cluster, שמגדיר כי כל ה-instances שאנו מעוניינים בהפעלתם ירוצו יחד לא רק באותו ה-availability zone, אלא גם ממש על אותו ה-rack. משמעות הדבר היא שמהירות הרשת שלנו תהיה אדירה כיוון שהם פיזית יימצאו אחד ליד השני, אך מצד שני במקרה של אסון\נפילת ה-infrastructure עצמו, אנו נאבד את ה-rack כולו ויחד איתו את כל השרתים שלנו בבת אחת. אופציה זו שימושית בעיקר עבור high-performance applications.
*Spread, שבו אנו עובדים בצורה הפוכה מ-cluster, שכן אנו רוצים למזער את סיכויי הנזק הפוטנציאלי בעת נפילת מערכות. במצב כזה כל ה-instances שלנו ירוצו על racks פיזיים שונים ובכך נייצור הפרדה מוחלטת ברמת החומרה ביניהם. במצב כזה אפשר גם לפרוס אותם על גבי מספר AZ's שונים - אך אנו מוגבלים על ידי AWS עד לכמות של 7 instances בכל AZ, בכל placement group. אופציה זו שימושית בעיקר עבור critical applications.
*Partition, מעין שילוב של שתי האופציות שהוצגו לפני כן, שבו אנו יכולים ליצור partitions שמכילים מספר EC2 בתוכם - וכל partition בעצם מייצג rack פיזי, אך ניתן לעבוד עם מספר partitions על גבי מספר AZ's. אופציה זו בעצם מאפשרת לנו להישמר מפני סכנות כמו נפילת rack שלם שכן ישפיע על מספר EC2 המוצבים עליו, אך זה לא יגרום לנפילת כלל המערכת שלנו, כיוון שיהיו לנו partitions נוספים המופרדים זה מזה מעצם טבעם - אופציה זו שימושית בעיקר עבור distributed applications. גם באופציה זו אנו מוגבלים בכמות של עד 7 partitions.


---
EBS
---
Elastic Block Store - אופציית אחסון המידע הדיפולטיבית שמגיעה יחד עם הקמה של EC2 - ברמת ברירת המחדל, מגיע EBS יחיד (נקרא root) בגודל 8GB שנמחק לבד בעת מחיקה של ה-EC2 אליו הוא מקושר (ניתן לשנות אופציה זו בעת הקמת ה-EC2 עצמו).
מקושר ל-EC2 ברמת הרשת ולכן ייתכן ויהיה latency במעבר נתונים ביניהם.
ניתן לקונפיגורציה באופן נפרד מ-EC2, וכן אפשר לחבר אותו רק ל-EC2 יחיד (ברמת certified cloud practitioner) , אך EC2 יחיד יכול להתחבר למספר EBS בו בזמן (יחס many to one בין מספר EBS לבין EC2 יחיד).
EBS Snapshots משמשים לשמירת מצב נתון של EBS, שנשמר גם בעת מחיקה של EBS מסויים - מהווים אופציה להעברת מידע בין שני AZ's, שכן אנו יכולים להעביר מידע מ-EBS ראשון ב-AZ אחד אל תוך סנאפשוט, ואז משם להעביר אותו ל-EBS שני ב-AZ אחר.
סוגים שונים של EBS Volumes כוללים:
*general purpose SSD - gp2/gp3 - אופציות הבסיס שמתאימות בתור cost-effective storage, מגיעות בתור root volume של EC2. ב-gp3 אפשר לשלוט בנפרד על (I/O Operations Per Second) IOPS ועל ה-throughput, וב-gp2 הם מקושרים יחד. יכולים להגיע עד מקסימום של 16,000 IOPS בכל מקרה.
*provision IOPS SSD - io1/io2 - לאפליקציות שדורשות יותר מ-16,000 IOPS, או למערכות קריטיות כדוגמת בסיסי נתונים. תומכים ב-EBS Multiattach. מגיעים עד מקסימום של 64,000 IOPS.
*hard disk drives (HDD) - st1/sc1 - לא יכולים להיות כאופציה בתור boot volume של root. ל-st1 יש התאמה גדולה יותר ל-big data / data  warehouses, ו-sc1 מתאים יותר למידע שלא ניגשים אליו לעיתים תכופות (cold HDD) ומגיע במחיר טוב.

באפשרותנו לקחת EBS Volume לא מוצפן ולהפוך אותו למוצפן בעזרת שיטה מעט עקיפה - לוקחים את ה-volume המקורי הלא מוצפן, לוקחים ממנו snapshot שגם הוא לא מוצפן, ואז עושים copy ל-snapshot הזה, ובשלב ההעתקה יש בידינו את האופציה לבחור להצפין את ההעתק - ולאחר שלב זה ניתן ליצור volume חדש שיהיה מוצפן כיוון שהוא נוצר מ-snapshot מוצפן. את ה-volume הזה אפשר לחבר לאיזה EC2 שנרצה ונוכל להמשיך כרגיל משם.
אופציה קצרה יותר אך זהה בתכליתה תהיה לקחת snapshot לא מוצפן, וליצור ממנו volume מוצפן על ידי בחירת encrypt this volume בעמוד ההגדרות בשעת היצירה שלו.

RAID- צורה מסויימת לשלוט בקונפיגורציית העבודה עם EBS Volumes, מתמקדים בעיקר בשתי אופציות:
RAID 0- מרוכז ביעילות performance; יוצר שכבה לוגית שמשלבת מספר EBS Volumes לכדי רמה אחת, כך שאם לדוגמה בידינו 2 EBS volumes ואנו כותבים כרגע 4 בלוקים של מידע, ייתכן ו-2 ילכו ל-volume אחד ו-2 ל-volume השני. בכך אנו מגבירים את ה-performance אך מסתכנים ב-fault tolerance.
RAID 1- מצב הפוך לקודם שתואר, כיוון שהאחד הזה יוצר מצב של mirroring; אנו בעצם מבצעים שכפול של כל מה שנכתב בין מספר EBS volumes, ומסתמכים על העובדה שבעת נפילה פוטנציאלית של אחד ממאגרי המידע, האחרים עדיין יעבדו וכל המידע שלנו עדיין יישמר במעין גיבוי. אופציה זו כן מצריכה שימוש כפול במעבר הנתונים שכן אנו עובדים במקביל מול 2 EBS volumes זהים.


---
EFS
---
Elastic File System - מערכת לניהול (network file system) NFS שיכולה להתפרש על פני מספר רב של EC2 וגם על פני AZ's רבים (לעומת EBS שמקושר ל-AZ יחיד).
יקר בערך פי 3 ממחיר gp2, אבל משלמים רק על מה שמשתמשים ולכן ייתכן שדווקא ייצא זול יותר בהתחשב בשימושים הספציפיים של המערכת.
מסוגל לעבוד רק עם AMI שמבוססים על לינוקס ולא על ווינדוס, ומצריך security groups על מנת לעבוד בכדי לווסת כניסה ויציאה של מידע ברשת על פני מספר EC2 הפזורים ברחבי AZ's שונים.
עובד מעולה במקרים בהם נצטרך להשתמש ביותר מ-EBS יחיד שעובד עם EC2 instance יחיד, כיוון שברגע שנתחיל לעשות scaling ולהשתמש ביותר EC2 instances ויותר EBS volumes, אם ניגש לאחד מהם ונשמור עליו מידע, דבר לא מבטיח שבגישה הבאה למערכת דרך ELB אכן ניגש ישירות לאותו EBS עבור המידע שלנו (חוסר stickiness), ולכן במצב כזה EFS יתאים לנו מאוד עבור מערכת distributed.


---
AMI
---
Amazon Machine Images - היכולת שלנו ליצור image של קונפיגורציית EC2 instance snapshot מסויים, ומשם לפתוח instances נוספים בעתיד שנוצרים בדיוק על פי הצרכים שלנו.
מאפשר לבצע הפעלה מהירה ויעילה יותר של instances כיוון שההתקנות וההכנות ההכרחיות מתבצעות בשלב מוקדם יותר.


---
ELB
---
Elastic Load Balancer - משמש עבור חלוקת input מידע עבור מספר EC2 בצורה נוחה ושווה, ובכך מהווה ונקודת כניסה מווסתת יחידה ביחס לעולם שמחוץ ל-instances שלנו ע"י חשיפה של DNS ולא ע"י חשיפת IP אינדיבידואלי של כל אחד מה-instances. 
ישנם מספר סוגים של ELB's:
*Classic Load Balancer, גרסה מ-2009 -     v1, תומך ב-HTTP, HTTPS, TCP. פועל ברמת שכבות 4/7 (application/transport layers). הגרסה הישנה ביותר, כבר יחסית outdated בימינו. לא תומך ב-SNI, לעומת ALB ו-NLB שכן תומכים.
*Application Load Balancer, גרסה מ-2016 - v2, תומך ב-HTTP, HTTPS, WebSocket. פועל ברמת שכבה 7 (application layer). מומלץ לשימוש כשאנו רוצים לבצע ניתוב ברמת requests בשימוש ב-target groups (לדוגמה test/ ו-login/ בסוף ה-URL של ה-ALB שלנו יכולים להוביל לנתיבים שונים על פי חוקים מסויימים שמוגדרים מראש). בנוסף, חשוב לדעת כי ניתן להשתמש באופציה שנקראת (Server Name Indication) SNI המאפשרת להשתמש ביותר מ-SSL Certificate יחיד עבור תעבורה של HTTPS.
*Network Load Balancer, גרסה מ-2017 -     v2, תומך ב-TCP, TLS (secure TCP), UDP. פועל ברמת שכבה 4 (transport layer). מהיר מאוד, מומלץ לשימוש כשאנו רוצים לבצע חלוקת input ברחבי קלאסטר של EC2 בצורה נוחה. יש להם elastic IP / fixed IP שאנחנו יכולים לקבוע מראש. לא כלולים ברמת ה-free tier של AWS.
*Gateway Load Balancer, גרסה מ-2020 -                לא הוסבר ברמת הקורס, חדש יחסית.

אפשר לקנפג ELB במוד Cross-Zone Load Balancing, מה שיממש בסופו דבר את ההחלטה האם לבצע חלוקה שווה של עבודה בין כל ה-EC2 instances שבידינו, ללא התחשבות ב-AZ's, או האם כן להתחשב ב-AZ's ואז כל ELB אחראי על חלוקה שווה בתוך ה-AZ אליו הוא שייך (ההחלטה היא פשוט שאלה האם אנו מעוניינים ב-pool אחד גדול של כל ה-EC2 שבידינו, או לא).
ב-ALB המוד הזה תמיד פעיל, אבל אין תשלום על מידע שעובר בין AZ's;
ב-NLB המוד הזה לא פעיל כברירת מחדל, אבל אם מעוניינים בהפעלתו אז הוא כן עולה מחיר מסויים עבור מעבר מידע בין AZ's;
ב-CLB ברירת המחדל תלויה באופן ההגדרה (דרך console לעומת CLI/API) אבל בכל מקרה אין תשלום עבור מידע העובר בין AZ's.
אפשר בנוסף לקנפג ELB's בתור internal או external, וההבדל הוא בין ELB שפועל פנימית, באופן פרטי רק בתוך המשתמש שלך, לבין ELB שיש לו גישה חיצונית לרשת הפומבית.

תקלות ידועות:
תקלות מסוג 4XX הן client induced errors.
תקלות מסוג 5XX הן application induced errors.
תקלה Load Balancer Error 503 משמעותה שה-ELB הגיע ל-capacity או שאין registered target.
אם ה-ELB אינו יכול להתחבר ל-application שלנו, יש לבדוק security groups.


---
ASG
---
Auto Scaling Groups, קבוצות של EC2 instances שיכולות לגדול או לקטון על פי alarm שמתריע בהתאם לחוקים שנקבעים מראש. יש להציב ערכי מינימום, מקסימום וכמות התחלתית של instances יחד עם החוקים הללו, ובכך אנו יוצרים מערכים שבאופן אוטומטי משנה את גודלה בהתאם לצרכי המערכת באותו רגע.
יודע להתייחס גם ל-IAM Roles, security groups, Key pairs, טיפול אוטומטי בטרמינציה של instances, טיפול אוטומטי ב-instances בעלי קישור unhealthy וכו'.
מטריקות טובות שניתן לבצע וויסות על פיהן:
*CPU Utilization - ערך ממוצע של שימוש ב-CPU ברחבי ה-instances שלנו.
*Request Count Per Target - איזון מסויים של כמות הבקשות הנשלחות לכל instance.
*Average Network In/Out - קיבולת הרשת העוברת בין ה-instances והרשת.
*Custom Metrics - ניתן תמיד לקבוע על פי צרכינו, דרך CloudWatch.
ישנו גם זמן Cooldown (כברירת מחדל מוגדר בתור 300 שניות) שקובע כי ברגע שמתקבע scale up / scale down כלשהו, לא ניתן לבצע פעולות scaling נוספות בזמן הנתון הזה. הסיבה לכך היא שנרצה לראות מה המצב הנוכחי לאחר יישום ה-scaling ובהתאם לעבוד משם. לשם כך גם מומלץ להרים את ה-instances שלנו מראש בעזרת AMI כך שזמן העלייה שלהם יהיה קצר יותר, ובכך נוכל להשיג מטריקות טובות יותר אודות ה-instances הפעילים שלנו ובהתאם לשנות את זמני ה-cooldown המוגדרים.
ASG שמחליט לבצע טרמינציה של אחד ה-instances המוכלים בו על פי החוקים המוגדרים, יבצע זאת באופן דיפולטיבי על פי בחירה של ה-AZ שמכיל הכי הרבה EC2 instances, ואז מתוכם יבחר את ה-instance בעל הקונפיגורציה הכי ישנה מתוכם.
מושג חשוב נוסף הוא lifecycle hook; עיקרון שעל פיו בעת עלייה או ירידה של EC2 instance ישנו זמן מסויים שה-instance עדיין לא עלה לחלוטין או ירד לחלוטין. אם לדוגמה אנו מחליטים ליישם lifecycle hook בעת עליית instance, הדבר אומר שנוכל עדיין לבדוק קונפיגורציות לפני שהמכונה נחשבת InService. באופן דומה אפשר להתייחס לזמן הורדת המכונה בעת Scale in על ידי פעולה אוטומטית מצד ה-ASG, ובזמן ה-lifecycle hook נוכל להוציא מידע חשוב מתוך המכונה לשם שמירה לעתיד,  לפני שהיא עוברת טרמינציה.


---
RDS
---
Relational Database Service, שירות של AWS שמאפשר ניהול של בסיסי נתונים בעזרת SQL בתור שפת query.
מאפשר עבודה עם בסיסי נתונים מהסוגים הבאים:
*Postgres
*MySQL
*MariaDB
*Oracle
*Microsoft SQL Server
*Aurora (לא ניתן כאופציה עבור השירות החינמי)
עבודה מול RDS היא על שירות EC2, אך אין באפשרותנו לבצע SSH לתוך המכונות שמריצות את בסיסי הנתונים, אך אנו כן יכולים לנהל את כל הפעולות הנדרשות מבחוץ.
RDS מבצע גיבויים אוטומטיים על פי maintenance window שאנו יכולים להגדיר, ובנוסף גם שומר transaction logs בכל 5 דקות, וכך יש בידינו את הכוח לחזור אחורה לנקודה מסויימת בזמן מה-backup הכי ישן שיש בידינו (עד הגבלה של 7 ימים שאפשר להגדיל אותה תיאורטית עד 35 ימים), ועד לחדש ביותר מלפני 5 דקות.
אנו יכולים גם לבצע DB Snapshots באופן ידני בתור משתמשי המערכת, ובכך לשמור מידע אחורה בזמן רחוק ככל שנרצה.
ברגע ש-RDS רואה שאנו עומדים לחרוג מגבולות גודל האחסון שהגדרנו בעצמנו בתחילת התהליך, RDS מסוגל להגדיל באופן אוטומטי את כמות האחסון על מנת שנוכל להמשיך לעבוד בנוחות מול בסיס הנתונים שלנו.

RDS Read Replicas משמשים במקרים בהם נרצה לבצע עבודת "קריאת מידע" (read) מתוך בסיס הנתונים שלנו, אך לא נרצה להאט את הפעולות השוטפות של האפליקציה מול בסיס הנתונים - במקרה כזה נוכל לייצר read replica שמתפקד בעצם כמעין העתק מוחלט של בסיס הנתונים בנקודת זמן מסויימת, ונוכל לבצע פעולות קריאת מידע (SELECT) עליו. read replicas אינם מתעדכנים בזמן אמת, אלא באופן אסינכרוני.
ישנה גם האופציה לקדם read replica להיות בסיס נתונים משל עצמו, אך אופציה זו נעשית באופן ידני על ידינו.
מבחינת מחירים של AWS, אם אנחנו מבצעים העברת מידע ל-read replica שנמצא ב-AZ אחר ממיקום ה-RDS DB instance שלנו אך אנחנו נמצאים עדיין בתוך אותו region, זה יישאר ללא עלות.
לעומת זאת, אם אנו חוצים regions בהעברה של מידע בין RDS DB לבין ה-read replica שלו, אנו כן נצטרך לשלם עבור שירות זה.

RDS Multi-AZ משמש אותנו במקרים בהן נרצה לשמור על availabilty גבוה של המידע בבסיס הנתונים שלנו, שכן שירות זה מאפשר לשמור מידע על גבי 2 AZ's בו בזמן.
מהלך זה מבוצע על ידי עדכון תמידי, synchronous, בין 2 בסיסי הנתונים. כל שינוי שמתבצע כשאנו ניגשים לאחד מהם (על ידי גישה דרך DNS יחיד שמבצע automatic failover במקרה הצורך) צריך לקבל אישור גם של בסיס הנתונים השני בכדי להתקבל ולהישמר בשניהם.

תיאורטית, זה אכן אפשרי להגדיר את ה-read replicas שלנו בתור Multi-AZ עבור מקרים של disaster recovery, ובכך נגרום ל-automatic failover במקרה הצורך.
על מנת לעבור ממצב של Single-AZ למצב של Multi-AZ אין צורך לעצור את בסיס הנתונים - אנו רק צריכים לשנות בהגדרות את האופציה בכדי לגרום לאופציה זו לפעול (מאחורי הקלעים מה שקורה זה שנלקח DB Snapshot של בסיס הנתונים המקורי, שממנו אנו יוצרים את ההעתק ב-AZ חדש, ואז מתבצע חיבור SYNC בין שניהם על מנת ליצור עדכונים חיים ובפועל עברנו כעת למצב Multi-AZ).

אם ברצוננו לבצע  הצפנה של המידע "at rest", כשהוא לא בתזוזה בין בסיסי נתונים, אנו צריכים להגדיר זאת בשעת ההגדרה ההתחלתית של בסיס הנתונים עצמו. read replicas לא יכולים להיות מוצפנים אם המאסטר אינו מוצפן.
לגבי מידע "in-flight", כשהוא בדרך מהאפליקציות שלנו אל בסיס הנתונים או חזור, RDS מצפין לבד באמצעות SSL Certificates.
בכדי להצפין בסיס נתונים ב-RDS אנו יכולים לעבוד בצורה דומה להצפנת EBS volumes - על ידי שימוש ב-snapshot של בסיס הנתונים הלא מוצפן, לאחר מכן ליצור copy של ה-snapshot ולהצפין אותו, ולבסוף לבצע שחזור של בסיס הנתונים מה-snapshot המוצפן.

אם אנו משתמשים ב-MySQL, Aurora או Postgres, החיבור בין ה-EC2 instance לבין בסיס הנתונים יכול להתבצע בעזרת auth token המתקבל בעזרת הגדרת IAM Role עבור ה-instance שלנו, שרק צריך להשיג את ה-token דרך שירות RDS, ומשם יוכל לשלוח את הבקשה לבסיס הנתונים ב-SSL ובעצם להזדהות מולו בחיבור פשוט יותר ובכך לחסוך שימוש בסיסמה.
הייחודיות של Aurora בתור שירות DB היא שהוא מכוון לשימוש בענן - הוא נחשב מהיר פי כמה דרגות מ-MySQL ו-Postgres כיוון שהוא cloud optimized.
בנוסף יש ביכולתנו לבצע one writer, many readers או לחילופין many writers בתור אופציות קוניפגורציה.
אם ברצוננו להגדיל באופן אוטומטי את כמות הבקשות המנוהלות בצד הקורא (דרך reader endpoint שמציג גישה יחידה לכל שירות הקריאה מבסיס הנתונים), ביכולתנו להשתמש בשירות Replicas Auto Scaling המייצר replicas שמאפשרים נקודות קריאה נוספות.
Aurora גם מסוגל להגדיל באופן אוטומטי את כמות האחסון המשותפת של כלל בסיס הנתונים (בקפיצות של 10 ג'יגה, עד מקסימום של 64 טרה).

ElastiCache יכול לשמש אותנו לשם שמירת מידע בצורת cache, שנחשבת מהירה ויעילה יותר מאשר לגשת בכל פעם לבסיס הנתונים עצמו בכדי לשלוף מידע מסויים.
אופציה זו יכולה לשמש במספר מקרים, כדוגמת common queries שנשלחים כבקשות קריאה לבסיס הנתונים באופן תכוף. במקום לגשת בכל query לבסיס הנתונים, נוכל במקום זאת לגשת ל-cache, לבדוק אם המידע הנדרש לנו נמצא בו ובהתאם לקחת משם או לפנות לבסיס הנתונים במקרה ולא. מידע זה יוכל להישמר ב-cache לשם שימוש עתידי עהנחה ו-query זה יתקבל בשנית.
דוגמה נוספת היא שמירה של user session state ובכך אפשר להפוך את האפליקציה שלנו ל-stateless. אופציה זו שומרת את כל קונפיגורציית השימוש של משתמש מסויים ברגע נתון, כך שגם אם מתנתק החיבור שלו מ-instance מסויים והוא עובר לאחר, ניתן יהיה לטעון את מידע ה-session הנשמר באופן קבוע ב-cache ובכך ליצור חווית שימוש טובה יותר.
השימוש ב-ElastiCache יכול להתבסס על גבי Redis או Memcached, שניהם אופציות שמירת ושליפת מידע מזיכרון באופן מהיר מאוד ולכן הם מתאימים כ-caches. שניהם גם open-source, ושניהם פועלים בצורת NoSQL השומרים מידע בתצורת key-value pairs.
Redis עובד בצורה דומה ל-RDS, בכך שהוא מייצר read replicas ושומר תמיד על high availabilty במידה ויש להחליף ביניהם במקרה הצורך, תומך בגיבויים ומסוגל לעבוד בצורת Multi-AZ עם Auto-Failover.
Memcached עובד בצורה שונה שנקראת sharding, שבה הוא עובד בצורה distributed ומחלק את המידע השמור במספר מקומות, אך אין ביכולתו לשמור גיבויים ואין בו replications בצורה מובנית. יתרון של Memcached הוא ארכיטקטורה multi-threaded, ולכן יכול להועיל במקרים בהם מדובר באפליקציות מסוג כזה.

CNAME - כתובת hostname שמכוונת לכתובת hostname אחרת, לדוגמה: 
app.mydomain.com -> blabla.anything.com
עובד רק עבור Non-Root Domains, לדוגמה- something.domain.com ולא רק- domain.com

Alias - כתובת hostname שמכוונת ל-AWS resource, לדוגמה:
app.mydomain.com -> blabla.amazonaws.com
עובד עבור Root Domains וגם Non-Root Domains. פעולה זו חינמית ומבצעת גם health checks.
לרוב עדיף להשתמש ב-alias כי הוא תופס את רוב המקרים, וגם חינמי.


-----------------
Elastic Beanstalk
-----------------
שירות של AWS שמאפשר להרים במהירות וביעילות סביבת עבודה שלמה שמשלבת אפליקציה קיימת שלנו יחד עם resources של AWS.
לדוגמה, השמה של אפליקציה קיימת ב-node.js על EC2 שמגיע מקונפג מראש, עם ELB's, ASG's, security groups וכו'.
Beanstalk הוא בעצם שילוב של Golden AMI (שמירת snapshot של מצב קיים לאחר התקנת אפליקציה נדרשת על instance מסויים בכדי ליצור image מסויים שממנו נוכל להרים מכונות באופן מהיר בעתיד) יחד עם הרמת כל קונפיגורציית ה-backend הנדרשת.


--
S3
--
Simple Storage Service, משמש אותנו לשמירה של אובייקטים שלמים בתצורת S3 buckets. אובייקטים יכולים להיות עד גודל של 5 טרה, אך בהעלאה יחידה אין באפשרותנו להעלות יותר מ-5 ג'יגה בכל פעם, ויש להשתמש ב-multi-part upload אם כן נעבור את הגודל הזה. גודל ה-bucket עצמו הוא תיאורטית לא מוגבל, והוא מבצע scaling up באופן אוטומטי, ולכן אין צורך להתייחס לנתון זה בעבודה שוטפת מול buckets.
יש באפשרותנו ליצור bucket נוסף שמקושר ל-bucket העבודה שלנו על מנת לעקוב אחרי audits, וזאת על ידי יצירה של אובייקטי log בכל פעם שמתבצעת פעולה כלשהי מול bucket העבודה שלנו. דבר חשוב מאוד שצריך להיזהר ממנו, זה לא להציב את bucket העבודה בתור audit bucket - דבר זה יגרום ללולאה אינסופית של יצירת אובייקטים של לוגים על פעולה מסויימת, ואז יצירת אובייקטים חדשים אודות אותם לוגים קודמים וכך הלאה.

ישנן מספר אפשרויות עבודה שונות עם S3, המתרכזות בעיקר בזמני אחסון האובייקטים ביחס לשימוש בהם:
*S3 Standard
*S3 Intelligent-Tiering
*S3 Standard-IA
*S3 One Zone-IA
*S3 Glacier
*S3 Glacier Deep Archive
אפשר לשנות את סוג ה-bucket איתו אנו עובדים עם אובייקטים מסויימים על ידי שימוש ב-lifecycle rules.

לכל אובייקט שמור בתוך bucket כלשהו יש key, שהוא בעצם ה-path בתוך שירות S3 עד אותו אובייקט, לדוגמה:
s3://my-bucket/my_file.txt , במקרה זה ה-key יהיה my_file.txt
במידה ויש "subfolders" בהיררכיה בתוך S3 (אפילו שאין באמת תיקיות בתוך S3 אלא רק ה-UI גורם לנו לחשוב כך), אז ה-key יהיה ה-path השלם, לדוגמה:
s3://my-bucket/my_folder1/another_folder/my_file.txt , במקרה זה ה-key יהיה my_folder1/another_folder/my_file.txt
keys מורכבים מחלוקה של prefix ו-object name בצורה הבאה:
Key: my_folder1/another_folder/my_file.txt
/Prefix: my_folder1/another_folder
Object Name: my_file.txt

בעת מחיקה של אובייקטים מתוך bucket, בלחיצת delete ראשונית על אובייקט מסויים הוא רק יסומן במה שנקרא "delete marker", שבעצם גורם לכך שהוא יוסתר מרשימת האובייקטים הכללית, ונוכל להביט בו רק אם נסמן את אופציית show versions לאחר שאפשרנו אותה ברמת הקונפיגורציה.
ברגע שנאפשר אופציה זו, נוכל לראות כי אותו delete marker הוא בעצם גרסה "מעודכנת" יותר של אותו אובייקט מקורי, ואם נסמן את ה-marker ונמחק אותו, בעצם נחזיר את האובייקט המקורי לרשימה הכללית. בכדי למחוק את האובייקט לחלוטין, נצטרך לסמן אותו עם ה-marker, ולאחר מכן לבצע מחיקה החלטית.

יש 4 דרכים לבצע encryption על הקבצים שאנו מעלים ל-S3:
*SSE-S3, בו המפתחות להצפנה מנוהלים על ידי S3 עצמו - ההצפנה מבוצעת server side, על ידי אלגוריתם ההצפנה AES-256. על מנת להפעיל הצפנה מסוג SSE-S3, יש לקבוע את ה-header לתצורת: "x-amz-server-side-encryption":"AES256".
*SSE-KMS, בו המפתחות להצפנה מנוהלים על ידי שירות KMS של AWS. ההצפנה מבוצעת server side. שירות זה נותן לנו שליטה לגבי ההחלטות למי יש גישה לאילו מפתחות, מאפשר לנו לשלוט על key rotation policy ונותן לנו audit trail. על מנת להפעיל הצפנה מסוג SSE-KMS, יש לקבוע את ה-header לתצורת: "x-amz-server-side-encryption":"aws:kms".
*SSE-C, בו המפתחות לנצפנה מנוהלים על ידי משתמש המערכת, שמספק אותם מחוץ ל-AWS.  ההצפנה בכל אופן מבוצעת server side. במצב זה S3 לא שומר את מפתחות ההצפנה לאחר השימוש בהם, ויש חובה להשתמש ב-HTTPS על מנת לשלוח את מפתחות ההצפנה בצורה encrypted in-transit בצורה זו, וזאת כדי ש-S3 יוכל לקבל את האובייקט ואת המפתח הנתון מהמשתמש ובכך יבצע הצפנה. גם בעת שליפת המידע על המשתמש להוסיף את מפתחות ההצפנה יחד עם הבקשה על מנת לגשת לאובייקט המוצפן.
*SSE-E, או Client Side Encryption, שבו המשתמש אחראי על הצפנת האובייקט לפני העלאתו אל תוך S3, ובכך המשתמש גם אחראי על פענוח ההצפנה לאחר שליפת האובייקט חזרה.

Cross-Origin Resource Sharing, CORS, מאפשר לנו לגשת לנתונים מ-origin שונה משלנו בעזרת  CORS Headers שיאפשרו גישה מסויימת מה-origin השני. דבר זה נעשה בעזרת Access-Control-Allow-Origin header. בהקשר לנושא זה, origin מוגדר בתוך scheme + host + port, לדוגמה https://www.example.com מכיל את הפורט 443 עבור https, ואת הדומיין example.
במקרה בו נרצה להשתמש בשיטת CORS, נצטרך להגדיר בקובץ ה-html ב-origin bucket שלנו את ה-fetch כדי לשלוף נתונים מ-origin אחר, אך בנוסף נצטרך גם ללכת להגדרות permissions ב-S3 bucket האחר ולהכניס שם קונפיגורציית json שאכן מאשרת ספציפית ל-origin הראשון לגשת אליו.

Cross Region Replication, CRR, מאפשר לנו לבצע asynchronous replication בין regions שונים, ו-Same Region Replication, SRR, מאפשר לנו את אותו הדבר רק ב-region יחיד.
בכדי לבצע replications נצטרך לפני כן לאפשר versioning בקוניפגורציית bucket המקור וגם ביעד - בנוסף לכך נצטרך גם לתת הרשאות מתאימות דרך IAM.
מרגע הפעלת replication בין buckets, רק אובייקטים חדשים שנוצרו מאותו רגע והלאה יועברו ל-bucket היעד, ולא אוביייקטים שנוצרו לפני כן. בנוסף, אנו יכולים לשלוט בקונפיגורציית bucket המקור האם אנו רוצים לבצע העתקה גם של delete markers בין ה-buckets.
אפשר לבצע replication בין buckets בחשבונות שונים.

אנו יכולים לעבוד עם עיקרון הנקרא Pre-Signed URL על מנת לגשת באופן ציבורי ל-resources מתוך buckets שאינם פתוחים לציבור.
דבר זה נעשה לדוגמה באופן אוטומטי בגישת הקליינט של AWS לתמונה מסויימת השמורה בתוך bucket שלנו באמצעות אופציית open (מאחורי הקלעים נוצר pre-signed URL על מנת לתת גישה ישירה שכזו). אם אנו ננסה לגשת ישירות ל-URL הרגיל של ה-bucket כשבסופו file_name.jpg שמהווה תמונה מסויימת השמורה בתוך ה-bucket, לא נצליח להיכנס כיוון שהגישה תהיה חסומה כי ה-bucket אינו ציבורי.
Pre-Signed URL משמש גם על מנת לתת הרשאה מוגבלת בזמן דרך URL מסויים, שכן לפעמים נרצה להגביל בזמן את ההרשאה לגשת באופן ציבורי ל-resource שנרצה שיהיה כמה שפחות חשוף.

באפשרותנו לקשר אירועים שמתרחשים באופן קבע ב-buckets שלנו למספר שירותים, כדוגמת SNS, SQS, Lambda. נוכל להציב מספר חוקים על אירועים שקורים בתוך buckets (מחיקה של אובייקט, הוספה של אובייקט, replication..) שעל פיהם יווצרו התראות שיישלחו במדיומים השונים.

אם ברצוננו לגשת למידע מסויים בתוך אובייקטים השמורים ב-buckets שלנו, אך איננו מעוניינים בהוצת כל הקבצים במלואם, באפשרותנו להשתמש ביכולת הנקראת Byte Range Fetch;
יכולת זו מאפשרת לנו לגשת לגודל מסויים של באפר ביטים מתוך הקבצים, במקום להתעסק בעבודה עם הקובץ המלא.

בעת שימוש רגיל עם buckets, הנושא של תמחור שמירת אובייקטים בתוך ה-bucket ושליחת מידע ברשת מתוך ה-bucket והחוצה לו נופל על ה-owner של אותו bucket.
יש בידינו אופציה להפעיל מוד שונה הנקרא Requester Pays, שבו שמירת האובייקטים עדיין נופלת על אחריות תשלום בידי ה-owner של ה-bucket, אך מחירי ה-networking עבור הורדת אובייקטים מה-bucket נופלים על ה-requester. במצב כזה ה-requester אינו יכול להיות אנונימי, שכן AWS צריכים לדעת את החשבון של מי לחייב עבור אותם חיובי network.

אם אנו מעוניינים ב-data analyzing ישירות מתוך ה-buckets שלנו, ללא צורך לבצע ייצוא של המידע לבסיס נתונים מסויים ולעבוד מולו, ביכולתנו להשתמש בכלי הנקרא Athena.
Athena עובד בצורה serverless, בשיטת SQL והוא בעל יעילות גבוהה עבור מגוון סוגי usecases.
התמחור בשימוש ב-Athena הוא per query and amount of data scanned.
אפשר להתחיל בעבודה עם Athena בצורה מאוד פשוטה, דרך מדריך עבודה ישיר בכתובת https://aws.amazon.com/premiumsupport/knowledge-center/analyze-logs-athena, שאמורה לספק לנו מספר queries שיאתחלו טבלה בבסיס נתונים דרך Athena, ומשם תגדיר את אותה טבלה להתאים לצרכינו.


-----------
CloudFront
-----------
Content Delivery Network, CDN, שמשפר את יכולת קריאת הנתונים שלנו באופן גלובלי על ידי יצירת caches בעזרת edge locations. אם לדוגמה מקור המידע שלנו נמצא באוסטרליה, ומשתמש מארה"ב רוצה לקרוא מהמידע הזה, נוכל ליצור נקודת cache בקרבת אותו משתמש על מנת להקל על אותו latency שעלול להיווצר עקב אותם מרחקים גדולים.
עבודה עם CloudFront נותנת לנו DDoS Protection, אינטגרציה עם AWS Web Application Firewall ו-Shield; בנוסף, היא מאפשרת לנו לחשוף חיצונית HTTPS endpoint, וגם לדבר בעזרת HTTPS באופן פנימי ב-backend.
אנו יכולים לעבוד עם פיצ'ר Origin Access Identity, OAI, שמאפשר לנו לשתף קונטנט private דרך CloudFront - בעזרתו אנו יכולים לגשת ל-resources כדוגמת S3 רק דרך CloudFront ולא דרך גישה רגילה.

ניתן לאפשר עבודה עם Signed URL או עם cookies עבור גישה פרטית למשאבי CloudFront שמגיעים מ-buckets. ההבדל ביניהם הוא ש-Signed URL הוא עבור פריט יחיד, בעוד ש-cookie מאפשר גישה לפריטים רבים בבת אחת וניתן לשימוש חוזר.
צריכים לזכור להגדיר expiration לשתי השיטות בכדי להגביל את זמני הגישה למשאבים שבידינו, אך כתלות בסוג המשאבים עצמם (מדיה להורדה יכולה להסתיים תוך דקות ולכן הגבלת הזמן על שיטת הגישת תוך להיות קצרה, לעומת משאב שידרוש גישה לטווחים ארוכים יוכל להסתמך על שיטת גישה שמאופשרת לטווח של שנים).

באפשרותנו לשלוט בכמות ה-edge locations שאנו עובדים מולם בשביל caching על מנת להפחית בעלויות השימוש בשירותי CloudFront:
*Price Class All - כל ה-edge locations, בבירור יתן לנו את הביצועים הטובים ביותר בצורה גלובלית אך גם תהיה האופציה היקרה ביותר.
*Price Class 200 - רוב ה-regions, פרט ל-regions היקרים ביותר.
*Price Class 100 - רק ה-regions הכי זולים (צפון אמריקה ואירופה).


---
SQS
---
Simple Queue Service, שירות שליחת הודעות בין services, על מנת ליצור מצב decoupled ביניהם. השירות בבסיסו כולל Producers של הודעות אשר נכנסות לתור, ו-Consumers השואבים הודעות מהתור ומוחקים אותן ממנו על מנת להתחיל בתהליך עיבודן.
Standard Queue - אין הבטחה לגבי סדר ההודעות בפנים, ויש לעיתים קריאה של יותר מפעם אחת לכל הודעה.
FIFO Queue - עובד בשיטת First In, First Out; מבטיח שמירה על סדר ההודעות כסדר זהה לכניסתן, וכל הודעה מעובדת פעם אחת בדיוק. בעל throughput נמוך מזה של התור הסטנדרטי עקב יתרונותיו. בעת בחירת אופציה זו בשלב הקונפיגורציה, עלינו לשים לב לקרוא לתור עצמו בשם כלשהו אך לסיים אותו עם "fifo." כדי לאפשר תחילת עבודה - לדוגמה, DemoQueue.fifo .

אין הגבלה לגבי מספר ההודעות הנשלחות או מספר ההודעות הנשמרות בתוך התור עצמו, אך גודל כל הודעה יכול להגיע עד  גודל של 256KB.
זמן החיים של הודעה בתוך התור באופן דיפולטיבי הוא 4 ימים, אך ניתן לשינוי ממינימום של דקה אחת ועד מקסימום של 14 ימים.

אנו יכולים ליצור מערכת scaling אוטומטית עבור ה-consumers שלנו, אם הם לדוגמה בתצורת EC2 instances, על ידי שימוש במטריקות כדוגמת ApproximateNumberOfMessages דרך CloudWach, אשר יתריע לנו כאשר כמות ההודעות המשוערת בתור מגיעה ל-threshold מסויים, בהתאם להוציא alarm, ולקשר את ה-alarm הזה ל-ASG שאוטומטית ירים EC2 instances  נוספים על מנת לבצע הרחבה אופקית.
בעת שליפת הודעה מתוך התור, נפתח טיימר שנקרא Message Visibility Timeout שברירת המחדל שלו היא 30 שניות, ומטרתו היא "להחביא" את ההודעה מ-consumers אחרים שהם לא האחד ששלף את ההודעה. אם תוך אותו זמן קצוב בטיימר ה-consumer לא מחק את ההודעה מהתור, היא "תחזור" לתור ו-consumers אחרים יוכלו לשלוף אותה ולעבד אותה בהתאם.
במידה וה-consumer מודע לעובדה שאותן הודעות שהוא שולף צריכות מעט יותר זמן בשביל תהליך העיבוד לפני שהטיימר שלהן יסתיים, הוא יכול להשתמש בקריאת ChangeMessageVisibiliy API בכדי לקבל זמן נוסף עבורן.
ישנה לולאה תיאורטית של הודעה שנכנסת לתור, הולכת ל-consumer ואז הוא לא מספיק לטפל בה ולמחוק אותה, ואז היא חוזרת שוב לתור, והכול חוזר על עצמו. במידה ולולאה זו חוזרת על עצמה מספר פעמים, אנו נרצה להוציא את ההודעה מהתור המקורי ולהעבירה לתור אחר, שנקרא Dead Letter Queue - מטרתו היא להחזיק את אותן הודעות שלא הצליחו לעבור באופן חלק את התהליך הנורמטיבי, ולכן יש לחקור ולהבין את מקורן. מומלץ לקנפג מראש את זמן החזקת הודעה בתוך ה-Dead Letter Queue ל-14 יום, שכן נרצה לאסוף בו הודעות מבלי שייעלמו לחלוטין ללא אנליטיקה שתבוצע עליהן.


---
SNS
---
Simple Notification Service, שירות שעובד על פי עיקרון pub/sub, המאפשר לנו לשלוח הודעה אחת ל-recievers מרובים בצורה נוחה ובעלת אינטגרציה לרוב שירותי AWS - כדוגמת CloudWatch alarms, ASG Notifications, S3 Bucket event, CloudFormation state changes וכו'.
מקור מידע מסויים יכול ליצור SNS Topic , שאליו יעדים רבים יכולים לעשות subscriptions ובכך להאזין לכל הודעה שנכנסת לאותו topic.
אפשר להחזיק עד 10 מיליון subscriptions עבור כל topic, ואפשר להחזיק עד 100 אלף topics שונים.
ה-subscribers עצמם יכולים להיות SQS, HTTP/HTTPS, Lambda, Emails, SMS Messages, Mobile Notifications.

מודל decoupled, סקאלאבילי קלאסי של שליחת הודעות בין מערכות שונות כולל שילוב של SNS יחד עם SQS:
נוכל ליצור הפרדה מוחלטת על ידי שליחת הודעה יחידה דרך SNS Topic, שלו יש מספר subscribers שהם SQS Queue, ומכל תור נוכל לשלוח את ההודעה בנפרד להמשך התהליך. בצורה כזו אנו תיאורטית יכולים להוסיף/להוריד תורים מבלי לפגוע בתכנון המערכת, ועדיין להישאר decoupled.
אפשר גם לבצע filtering על ידי שימוש ב-JSON Policies בכדי ליצור פילטרים מסויים לגבי אותם subscriptions.